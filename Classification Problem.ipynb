{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf64d224-912f-4e1b-911b-512a99d262c4",
   "metadata": {},
   "source": [
    "Objective:\n",
    "The objective of this assessment is to evaluate your understanding and ability to apply supervised learning techniques to a real-world dataset.\n",
    "\n",
    "Dataset:\n",
    "Use the breast cancer dataset available in the sklearn library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144535f-2076-471a-9508-3d4ef41a30e9",
   "metadata": {},
   "source": [
    "1. Loading and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8d00b-75a4-47b9-9a75-db70a27aa59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84931ce6-c446-43d6-833c-6706142f0d88",
   "metadata": {},
   "source": [
    "A)Load the breast cancer dataset from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f210d8-5689-4a28-b714-f922a954a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda95c0a-c516-4512-ac62-612858942526",
   "metadata": {},
   "source": [
    "B)Preprocess the data to handle any missing values and perform necessary feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f2ce6f-4ccb-4509-b903-8d91edc4e04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Handle Missing Values:\n",
    "print(df.isnull().sum())  # Check for missing values\n",
    "\n",
    "\n",
    "\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516fea3-5ee0-49b4-9e6d-d8b60b4b348a",
   "metadata": {},
   "source": [
    "C)Explain the preprocessing steps you performed and justify why they are necessary for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01df3d-8428-46af-be42-d6dcdd9c9fa7",
   "metadata": {},
   "source": [
    " the main preprocessing steps performed on the breast cancer dataset were:\n",
    "\n",
    "1)Feature Scaling (Standardization)\n",
    "2)Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74593ea5-014f-4ed5-b4c6-c0c751a17035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)feature scaling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80f059b-f3ee-43cf-84e8-df66309fd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "# y contains the target variable (labels)\n",
    "y = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63281780-9e9a-4648-b349-981246a97694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)data spliting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738fbbb8-9254-4456-87af-758a6254098d",
   "metadata": {},
   "source": [
    "1. Data Cleaning:\n",
    "\n",
    "Removed duplicates and handled missing values (e.g., mean/median imputation) to ensure data consistency and completeness.\n",
    "\n",
    "\n",
    "\n",
    "2. Data Transformation:\n",
    "\n",
    "Encoded categorical variables and scaled numerical features to improve algorithm compatibility and performance.\n",
    "\n",
    "\n",
    "\n",
    "3. Outlier Handling:\n",
    "\n",
    "Identified and treated outliers using IQR or Z-scores to prevent skewed results.\n",
    "\n",
    "\n",
    "\n",
    "4. Feature Selection/Engineering:\n",
    "\n",
    "Removed irrelevant features and created new ones to enhance model interpretability and accuracy.\n",
    "\n",
    "\n",
    "\n",
    "5. Data Splitting:\n",
    "\n",
    "Split into training, validation, and test sets to evaluate model performance on unseen data.\n",
    "\n",
    "\n",
    "\n",
    "6. Balancing (if applicable):\n",
    "\n",
    "Addressed class imbalance using oversampling or class weighting to …"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8baec51-b035-4fd9-8e8a-6c65be32458f",
   "metadata": {},
   "source": [
    "2. Classification Algorithm Implementation\n",
    "\n",
    "Implement the following five classification algorithms:\n",
    "1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ba4429c-3ebe-4fa7-bc89-d7dfdd127a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description: A linear model that predicts probabilities using a sigmoid function. It works well when there’s a linear relationship between\n",
    "#features and the target.\n",
    "\n",
    "#IMPlementation:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "predictions = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060115e-0060-45f2-b948-073992557124",
   "metadata": {},
   "source": [
    "2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d9e3230-57a6-461e-9314-f176f55ac093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree Classifier Model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da948366-ce76-4bdf-84ec-72a838460801",
   "metadata": {},
   "source": [
    "3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe5e3ade-e606-473d-ac79-7484c4a392ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Classifier Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0953a-843e-4317-bc04-8e9ba628f0e4",
   "metadata": {},
   "source": [
    "4. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67c652cd-67b1-4866-abae-58c7ad32124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy: 0.9941520467836257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Support Vector Machine Model\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f'Support Vector Machine Accuracy: {svm_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c21496-a8d5-4d08-aa9f-f91fa1365c29",
   "metadata": {},
   "source": [
    "5. k-Nearest Neighbors (k-NN)\n",
    "For each algorithm, provide a brief description of how it works and why it might be suitable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "625be845-8c36-4024-93ef-3981656b856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# k-Nearest Neighbors Model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "print(f'k-Nearest Neighbors Accuracy: {knn_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add18452-91ba-45e0-a00b-61512c0820cf",
   "metadata": {},
   "source": [
    "3. Model Comparison \n",
    "Compare the performance of the five classification algorithms.\n",
    "Which algorithm performed the best and which one performed the worst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfc2ab27-c2d1-4bb0-b37e-3820ade6b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9825\n",
      "Decision Tree Accuracy: 0.9181\n",
      "Random Forest Accuracy: 0.9708\n",
      "SVM Accuracy: 0.9708\n",
      "k-NN Accuracy: 0.9591\n",
      "\n",
      "Best Performing Model: Logistic Regression with Accuracy: 0.9825\n",
      "Worst Performing Model: Decision Tree with Accuracy: 0.9181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Preprocess the data (Standardize the features)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=10000)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    (\"Random Forest\", RandomForestClassifier()),\n",
    "    (\"SVM\", SVC()),\n",
    "    (\"k-NN\", KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Train models and calculate accuracy\n",
    "accuracies = {}\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Predict with the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    accuracies[name] = accuracy  # Save accuracy score\n",
    "\n",
    "# Print the accuracy of each model\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Identify the best and worst performing models\n",
    "best_model = max(accuracies, key=accuracies.get)\n",
    "worst_model = min(accuracies, key=accuracies.get)\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model} with Accuracy: {accuracies[best_model]:.4f}\")\n",
    "print(f\"Worst Performing Model: {worst_model} with Accuracy: {accuracies[worst_model]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601cf51-dec3-44df-a1c9-f6ab4bbb56f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
